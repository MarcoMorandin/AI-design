we conduct a preliminary study showing that autocorrelation-based features capture distance-related information by analyzing how an audio clip interacts with room impulse responses (RIRs) recorded at different distances; (3) we validate the effectiveness of the proposed features on real data.

## II Proposed Reverberation-based Features

Log-mel spectrograms and intensity vectors (IVs) work well for SED and DOAE but are not suited for distance estimation. To address this, we introduce two input features specifically designed to enhance distance estimation.

### _Direct-to-Reverberant Features_

Distance cues can be extracted from the relationship between the direct and reverberant components of the captured audio signals [17]. To estimate the direct sound, \(d(t)\), we employed the Weighted Prediction Error (WPE) dereverberation algorithm [23] applied to the omnidirectional channel W of the first-order ambisonic (FOA) audio format. Specifically, we adopted the Python implementation of the WPE algorithm released by Drude _et al_. [24] (taps=60; delay=5; iterations=5). The reverberant component, \(r(t)\), is then estimated by subtracting the direct signal from the original signal in the temporal domain. To extract DRR features as 2D inputs to the model and to enable concatenation with the other SELD features (i.e., log-mel spectrograms and IVs), we calculate the DRR as a function of time and frequency, and then mapped it to log-mel space. The proposed DRR input features, \(\mathbf{DRR}^{\mathrm{mel}}\), are defined as:

\[\mathbf{DRR}^{\mathrm{mel}}(t,k)=10\cdot\log_{10}\left(\mathbf{P}_{\mathrm{ DRR}}^{\mathrm{mel}}(t,k)\right) \tag{1}\]

\[\mathbf{P}_{\mathrm{DRR}}^{\mathrm{mel}}(t,k)=\sum_{f=0}^{F}\mathbf{H}^{ \mathrm{mel}}(k,f)\left(\frac{\mathbf{P}_{\mathrm{D}}(t,f)}{\mathbf{P}_{ \mathrm{R}}(t,f)}\right) \tag{2}\]

where \(\mathbf{H}^{\mathrm{mel}}\) denotes the mel filter bank, which maps the frequency spectrum to the mel scale, with \(k\) being the mel bin index. \(\mathbf{P}_{\mathrm{D}}(t,f)\) and \(\mathbf{P}_{\mathrm{R}}(t,f)\) are the power spectral densities (PSDs) of the direct and reverberant components, respectively. To prevent instability and avoid division by zero, the PSD values were clamped to a small positive constant, \(\epsilon\)=\(1e{-}10\). Mathematically, \(\mathbf{P}_{\mathrm{D}}(f,t)\) and \(\mathbf{P}_{\mathrm{R}}(f,t)\) can be defined as \(\mathbf{P}_{\mathrm{D}}(t,f)\)=\(\max(|\mathbf{D}(t,f)|^{2},\epsilon)\) and \(\mathbf{P}_{\mathrm{R}}(t,f)\)=\(\max(|\mathbf{R}(t,f)|^{2},\epsilon)\), where \(\mathbf{D}(t,f)\) and \(\mathbf{R}(t,f)\) are the short-term Fourier transforms (STFTs) of the direct and reverberant components, \(d(t)\) and \(r(t)\), respectively.

In addition to the DRR features described, we explore a variant where \(\mathbf{D}(t,f)\) and \(\mathbf{R}(t,f)\) are separately converted into log-mel spectrograms and fed into the model. This approach, introduced in our DCASE2024 Task 3 submission [25], aims to give the network greater flexibility in learning task-relevant information. We refer to these features as D+R features.

### _Short-term Power of the Autocorrelation_

For the second feature, we explore the role of early reflections in distance estimation, focusing on the ITDG, a key cue for perceiving distance [26, 27]. While early reflection delays also depend on room size, it is reasonable to assume that the earliest reflection originates from the floor [27], as shown in Fig. 1. From this assumption, Table I demonstrates that ITDG from floor reflections decreases as the source-microphone distance increases. These values assume a microphone height of \(h_{m}\)=\(1.5\)m, as in the STARSS23 dataset [7], and a source height of \(h_{s}\)=\(0.9\)m, reflecting the average event height in the training set, similar to a seated user. We also include sources at 1.5m, representing standing speakers. Although these conditions may not always hold, we argue that the model can learn prior knowledge about typical source heights based on class. For instance, speech is unlikely to originate from the ceiling or floor, whereas footsteps are naturally associated with the ground. Ideally, the model should determine when and how to incorporate such priors to refine distance estimation.

To design an input feature that captures early reflections, we conducted a preliminary study on ITDG variations across different source distances. We analyzed an 8s speech clip from the S3A Object-based Audio Drama dataset [28, 29] and convolved it with room impulse responses (RIRs) from SurrRoom 1.0 [30]. Specifically, we used the omnidirectional W channel of FOA RIRs recorded in the "Pop_Recording_Studio" at distances of [1m, 1.5m, 2m, 2.5m, 3m].

Fig. 2 shows the aligned RIRs, where the first reflection, i.e., the initial peak after the direct sound, shifts closer to the direct sound as distance increases, consistent with Table I. A later strong reflection, likely from the rear wall, also appears, with increasing delay at greater distances. While wall reflections depend on room size and geometry, making them unreliable for distance estimation, floor reflections offer a more robust and consistent cue for this task.

After spatializing the clip at different distances, we compute

Fig. 1: Floor reflection path when source and receiver are at the same height (\(h_{s}\)=\(h_{m}\)) and separated by distance \(d\).

\begin{table}
\begin{tabular}{c||c|c|c||c|c|c} \cline{2-7}  & \multicolumn{3}{c||}{**Source Height: 1.5m**} & \multicolumn{3}{c}{**Source Height: 0.9m**} \\ \hline
**Dist** & **Direct** & **1stRef** & **ITDG** & **Direct** & **1stRef** & **ITDG** \\ \hline
1.0 m & 2.9 ms & 9.2 ms & 6.3 ms & 3.4 ms & 7.6 ms & 4.2 ms \\
1.5 m & 4.4 ms & 9.8 ms & 5.4 ms & 4.7 ms & 8.2 ms & 3.5 ms \\
2.0 m & 5.8 ms & 10.5 ms & 4.7 ms & 6.1 ms & 9.1 ms & 3.0 ms \\
2.5 m & 7.3 ms & 11.4 ms & 4.1 ms & 7.5 ms & 10.1 ms & 2.6 ms \\
3.0 m & 8.7 ms & 12.4 ms & 3.6 ms & 8.9 ms & 11.2 ms & 2.3 ms \\ \end{tabular}
\end{table} TABLE I: Ideal direct sound and first reflection (1stRef) delays, with their corresponding initial time delay gaps (ITDGs), as the source distance increases, assuming the first reflection originates from the floor. We present cases for source heights of 1.5 m and 0.9 m, with microphone positioned at 1.5 m, sound speed of 343 m/s, and no additional interfering factors.

