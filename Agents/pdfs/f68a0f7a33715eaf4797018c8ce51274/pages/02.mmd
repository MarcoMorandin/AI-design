braries for audio DSP. The primary aim of this review was to assess the landscape of available tools and their capabilities, particularly concerning GPU acceleration, which is increasingly important for handling complex audio processing tasks.

The research questions guiding our investigation were meticulously crafted to provide a comprehensive understanding of the current offerings:

* How many GPU-accelerated libraries have been released for Python?
* What functionalities do these libraries offer?
* How is their interface designed?

To address these questions, we utilized the Scopus search engine to perform a systematic literature review. The inclusion criteria were defined using the search query: TTILE-ABS-KEY ( ( ( signal AND processing ) OR dsp ) AND( library OR package OR software ) AND ( audio OR sound OR music ) ) AND PUBYEAR > 2007 AND PUBYEAR < 2025. The starting point of 2008 was chosen to coincide with the first stable release of Python 3.0, marking a significant evolution in Python's capabilities, while 2025 was excluded as it is yet to conclude. The inclusion of terms such as "library," "package," and "software" was strategic, ensuring a focus on software tool implementations and excluding generic DSP processes without a designated interface for further development by other programmers.

Our search yielded 2431 papers on digital signal processing libraries for audio published between 2008 and 2024. Of these, 119 were available in Python, with only 10 primarily focusing on GPU acceleration [4, 5, 6, 7, 8, 9, 10, 11]. This indicates a relatively limited focus on leveraging GPU capabilities within the Python DSP community.

Subsequently, we refined our selection by excluding articles not directly related to audio DSP or the specific development of libraries, whether GPU or CPU-based. The final selection comprised papers associated with the most widely used libraries in the audio domain, as summarized in Table 1. The table provides a detailed overview of the libraries, their associated papers and authors, and key characteristics such as GPU acceleration, the level of the API (high or low), the availability of explicit filter implementations, and the capability for signal analysis.

The analysis of this survey reveals a notable lack of interest within the scientific community in releasing efficient libraries for signal processing, with a tendency to develop ad-hoc solutions that are not adequately shared or valorized. Considering the substantial body of research related to DSP, it would be prudent to systematically collect and share such software with the broader community. Furthermore, none of the solutions identified in the survey provide an object-oriented interface, instead relying on interfaces derived from MATLAB functions [14]. This highlights a significant gap in the availability of user-friendly, modular, and extensible DSP libraries that can fully exploit the capabilities of modern computing architectures, such as GPUs, while offering an intuitive development experience.

## 3 Design principles and core features

Inspired by the design paradigm established by torchaudio [5], which is widely regarded as the standard for deep learning applications involving audio, our objective was to implement a distinct class for each filter type to ensure seamless compatibility with torchaudio.

To promote a more object-oriented methodology for audio manipulation, we encapsulated both the signal and its sampling frequency within a single class, Wave. Within this class, we overloaded the OR operator to function similarly to a pipe operator, akin to that used in Bash. This design choice marks a departure from the conventional representation of audio signals in existing libraries, which typically provide the sample array and sampling frequency as separate entities, with the frequency being utilized only during signal manipulation. Given that numerous discrete algorithms necessitate knowledge of the sample rate, the approach adopted by torchfx (similar to that proposed by the pydub library) ensures that these discrete parameters remain transparent and consistent throughout the program's execution. This design also mitigates potential bugs arising from omitted parameters; for example, the librosa [13] library often defaults to a sampling frequency of 22050 Hz. Additionally, the creation of the class facilitates operator overloading and the inclusion of supplementary methods.

In torchfx, we have leveraged the strengths of torchaudio and extended its interface. Essentially, the Transforms library within torchaudio offers several implementations of transformations applicable to signals (e.g., Resample for altering the sampling rate or Vol for adjusting signal gain), alongside enabling transitions between the time domain and frequency domain using algorithms such as Short-Time Fourier Transform (STFT), Mel spectrogram extraction, and the Griffin-Lim algorithm.

The section pertaining to IIR and FIR filters, however, does not implement a similar interface and is instead confined to the functionals module of torchaudio, which emulates a MATLAB-style interface1. This module does not offer default implementations of various filter types (e.g., Butterworth, peaking, Chebyshev, shelving) but instead provides a single generic function, lfilter, which requires the user to supply filter coefficients. Our aim was to develop a foundational implementation of various FIR and IIR filter types through an object-oriented interface analogous to the transformations provided by torchaudio, thereby ensuring compatibility with modules used for constructing neural networks, based on the nn.Module class provided by PyTorch.

Figure 1: Scientific Literature on DSP Software (2008â€”2024)

