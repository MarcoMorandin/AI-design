"WEBVTT\n\n1\n00:00:00.000 --> 00:00:05.360\nfrom now on as this Latin vector ht.\n\n2\n00:00:05.360 --> 00:00:09.860\nOne thing I can do is that,\n\n3\n00:00:09.860 --> 00:00:14.400\nthe Latin representation that I used to\n\n4\n00:00:14.400 --> 00:00:21.240\nrepresent the word interesting depends not only on the input,\n\n5\n00:00:21.240 --> 00:00:23.200\nbut also depends on the context,\n\n6\n00:00:23.200 --> 00:00:25.040\nso what we have seen before.\n\n7\n00:00:25.040 --> 00:00:27.280\nOut of this Latin representation,\n\n8\n00:00:27.280 --> 00:00:34.400\nmaybe I can plug some MLP or something that allows me to build a classifier.\n\n9\n00:00:34.400 --> 00:00:44.500\nSo usual scheme, softmax, and maybe some cross entropy loss to build the classifier on the top of this.\n\n10\n00:00:44.500 --> 00:00:53.500\nSo somehow we know what we can plug here. We don't know exactly yet what can be here, but we will see shortly.\n\n11\n00:00:53.500 --> 00:01:09.540\nBut what is new, this is kind of quite simple, what is new is that for the first time we are not addressing as in feedforward neural network a single input, single output problem, even if in the case of\n\n12\n00:01:10.120 --> 00:01:13.660\nconvolutional neural network this single input is\n\n13\n00:01:13.660 --> 00:01:22.020\nis still structured and also the output can be structured.\n\n14\n00:01:22.020 --> 00:01:24.140\nBut here we are interested into something like that,\n\n15\n00:01:24.140 --> 00:01:27.640\nwhere we have multiple inputs and I\n\n16\n00:01:27.640 --> 00:01:31.060\nneed to capture the relationship in one single output.\n\n17\n00:01:31.060 --> 00:01:33.640\nAnd this is what I want to process\n\n18\n00:01:33.640 --> 00:01:37.440\nwith the recurrent neural network.\n\n19\n00:01:37.440 --> 00:01:40.560\nOf course, one of the strengths of recurrent neural network\n\n20\n00:01:40.560 --> 00:01:46.800\nthen they can be applied also to, they are very flexible. For instance, image captioning is a very\n\n21\n00:01:46.800 --> 00:01:55.120\ndiverse problem. So as input you have an image and as output you have a sequence of variable length,\n\n22\n00:01:55.120 --> 00:02:03.680\nin this case will be the caption the kids are jumping. But even in this situation I can imagine\n\n23\n00:02:03.680 --> 00:02:07.560\nthat I can build something where I capture the context\n\n24\n00:02:07.560 --> 00:02:12.400\nwith my, again, context vectors or my either representation\n\n25\n00:02:12.400 --> 00:02:16.200\nH0, H1, H2, H4.\n\n26\n00:02:16.200 --> 00:02:19.700\nHowever, the design of the recurrent neural network,\n\n27\n00:02:19.700 --> 00:02:35.761\neven if the underlying dependency structure is the same it different because as input you have an image And we may know that a way to encode an image is by getting the latent representation obtained for instance by a pre\n\n28\n00:02:35.761 --> 00:02:41.121\nconvolutional neural network. This will produce some representation that together with the\n\n29\n00:02:41.121 --> 00:02:49.981\nrepresentation associated with this start sentence can be used to build multiple classifier and the\n\n30\n00:02:49.981 --> 00:02:54.341\nmultiple classifier will be used to predict the next word.\n\n31\n00:02:55.001 --> 00:02:59.841\nSo what is happening here is that the word kids is predicted\n\n32\n00:02:59.841 --> 00:03:02.401\nbecause the word before was there\n\n33\n00:03:02.401 --> 00:03:11.241\nand because the context tells me that I'm interested in describing with words\n\n34\n00:03:11.241 --> 00:03:15.061\nthis picture that I have encoded with CNN.\n\n35\n00:03:15.641 --> 00:03:18.701\nThe same for the other words.\n\n36\n00:03:18.701 --> 00:03:23.741\nyou know, jumping is predicted thanks to the previous context and the previous context not only\n\n37\n00:03:23.741 --> 00:03:31.581\nintegrate the previous words but also the representation of the CNN and so on until\n\n38\n00:03:31.581 --> 00:03:38.061\nI predict a symbol that is associated to the word end of sentence or stop or whatever.\n\n39\n00:03:39.421 --> 00:03:45.821\nWhat is different is that this time I have a single input and multiple output but I can still\n\n40\n00:03:45.821 --> 00:03:52.061\ndeal with the same tool and the tool is a recurrent neural network. So before we had\n\n41\n00:03:52.061 --> 00:03:58.061\nmultiple input, single output, and now we have single input, multiple output. However,\n\n42\n00:03:58.701 --> 00:04:03.101\nthis internal dependency structure is still the same.\n\n43\n00:04:07.341 --> 00:04:11.661\nIn the next two lessons, I will talk a lot about machine translation because\n\n44\n00:04:11.661 --> 00:04:21.041\nBecause machine translation is where a lot of progress was made towards advancing foundation models and transformers.\n\n45\n00:04:21.041 --> 00:04:29.321\nAnd if we talk about machine translation, we also have a problem of dealing with sentences of different lengths.\n\n46\n00:04:29.921 --> 00:04:39.401\nAnd in particular, this is even more complicated because we have a sentence as input of variable length and a sentence as output of variable length.\n\n47\n00:04:39.401 --> 00:04:46.821\nSo this is what will enable me to translate a sentence from English to French, for instance.\n\n48\n00:04:46.821 --> 00:05:05.762\nAnd of course the different I mean this is obvious I mean the different the same meaning can be expressed with different words into different languages so this cannot be operated by translating each word\n\n49\n00:05:07.362 --> 00:05:13.602\none at a time. This is especially important because this will lead me next time to attention\n\n50\n00:05:13.602 --> 00:05:22.362\nmodel. However, the fact that I'm predicting le, for instance, it's an effect of the fact\n\n51\n00:05:22.362 --> 00:05:28.242\nthat before I had bonjour, but it's also an effect of the fact that before I have captured\n\n52\n00:05:28.242 --> 00:05:42.282\nsome context associated to the English translation. I'm talking about the same modeling tool and\n\n53\n00:05:42.282 --> 00:05:50.142\nIn principle, even if this toy example is a real toy, what I really want is to have\n\n54\n00:05:50.142 --> 00:05:54.882\nthese methods to work when I have a very long sentence.\n\n55\n00:05:54.882 --> 00:05:59.242\nSo this will be actually the challenge for the next two lessons.\n\n56\n00:05:59.242 --> 00:06:07.402\nSo what people have done to deal progressively with longer and longer sequences.\n\n57\n00:06:07.402 --> 00:06:12.642\nSo this is also new with respect to what we have seen before because I have still a recurrent\n\n58\n00:06:12.642 --> 00:06:17.402\nneural network but this time should model something that is multiple to multiple.\n\n59\n00:06:17.402 --> 00:06:24.402\nSo multiple input, multiple output capturing some form of contextual information here.\n\n60\n00:06:24.402 --> 00:06:29.442\nLast application that I wanted to show you and there is a reason why I chose this four\n\n61\n00:06:29.442 --> 00:06:35.302\nbecause they correspond to four different design of a recurrent neural network is this\n\n62\n00:06:35.302 --> 00:06:36.982\nvideo frame classification.\n\n63\n00:06:36.982 --> 00:06:41.182\nSo we are given a video clip and I want to predict a sequence of labels.\n\n64\n00:06:41.742 --> 00:06:50.742\nThis time, it's if you want a simpler case, because given a certain input, I want to predict the label associated to the previous input.\n\n65\n00:06:50.742 --> 00:06:57.742\nOf course, I can do this in isolation, but it will be still better to model some contextual information,\n\n66\n00:06:57.742 --> 00:07:01.142\ninformation because of course, the label that I'm predicting\n\n67\n00:07:01.142 --> 00:07:06.142\nat the previous step will be clearly dependent on the label\n\n68\n00:07:06.142 --> 00:07:07.802\nthat I predicted previously.\n\n69\n00:07:07.802 --> 00:07:10.482\nSo having a recurrent neural network to predict,\n\n70\n00:07:10.482 --> 00:07:14.022\nto handle this frame classification problem\n\n71\n00:07:14.022 --> 00:07:15.222\nis also a good idea.\n\n72\n00:07:15.222 --> 00:07:28.003\nAnd this is different from a machine translation because for each frame I need to do a prediction and it not that I finish a sentence I build the context and I translate\n\n73\n00:07:29.003 --> 00:07:37.563\nOkay, so long story short, we have seen four applications that show clearly the flexibility of recurrent neural network\n\n74\n00:07:37.563 --> 00:07:44.043\nthat can be used for dealing with the input and output of various lengths.\n\n75\n00:07:44.763 --> 00:07:51.802\nIn particular, multiple to single, single to multiple, and multiple to multiple in two\n\n76\n00:07:51.802 --> 00:07:58.123\ndifferent flavors. This is the flavor of video frame prediction, this is the flavor of machine\n\n77\n00:07:58.123 --> 00:08:06.922\ntranslation. This picture is also interesting because it somehow leads me to think that\n\n78\n00:08:06.922 --> 00:08:13.242\nand RNN is a composition of multiple individual blocks. And what we are interested in is actually\n\n79\n00:08:13.242 --> 00:08:18.922\nin understanding what is in this individual block. And for today we are discussing the\n\n80\n00:08:18.922 --> 00:08:25.163\nimplementation of this individual block in the naive way, so with the vanilla recurrent neural\n\n81\n00:08:25.163 --> 00:08:29.962\nnetwork, and then some more sophisticated implementation of this individual block\n\n82\n00:08:29.962 --> 00:08:36.683\nthat are with LSTM and GRU. So what is inside each of these individual blocks?\n\n83\n00:08:36.683 --> 00:08:46.523\nThis is what is inside each individual block. So in principle, a RNN is the first neural network\n\n84\n00:08:46.523 --> 00:08:51.643\nthat we are encountering with Cycle because before, if you remember, we have always defined\n\n85\n00:08:51.643 --> 00:09:01.723\na neural network as a way to process the information in a direct fashion, so from the input to\n\n86\n00:09:01.723 --> 00:09:02.723\nthe output.\n\n87\n00:09:02.723 --> 00:09:12.443\nHere instead we have a kind of recursive behavior that somehow indicates the fact that the latent\n\n88\n00:09:12.443 --> 00:09:18.703\nrepresentation at time t plus one is dependent on the latent representation at previous time.\n\n89\n00:09:18.703 --> 00:09:29.282\nAnd then we have some input signal that is, you know, some that is associated to our input\n\n90\n00:09:29.282 --> 00:09:35.763\nsequence and then sometimes on the top of the latent representation we build the classifier\n\n91\n00:09:35.763 --> 00:09:41.083\nand the classifier is no magic because it's the usual you can implement this by having\n\n92\n00:09:41.083 --> 00:09:46.203\na linear layer softmax and then as I told you, cross entropy if you want to design a\n\n93\n00:09:46.203 --> 00:09:48.542\nloss on the top of this.\n\n94\n00:09:48.703 --> 00:09:49.943\nSo,\n\n95\n00:09:49.943 --> 00:09:54.943\nSo let's go a bit into what is exactly this ht.\n\n96\n00:09:55.343 --> 00:09:58.183\nSo it's a neural network.\n\n97\n00:09:58.183 --> 00:10:03.183\nSo we are describing this ht as an linear function\n\n98\n00:10:04.223 --> 00:10:07.583\nof the input xt and of the previous\n\n99\n00:10:07.583 --> 00:10:10.983\nlatter representation f time t minus one.\n\n100\n00:10:10.983 --> 00:10:14.663\nSo, as I said, this is a neural network.\n\n101\n00:10:14.663 --> 00:10:17.423\nSo it's quite obvious,\n\n102\n00:10:17.423 --> 00:10:19.383\nbut we will see in the next few slides\n\n103\n00:10:19.383 --> 00:10:27.463\nthis will contain some fine transformation and on the top of the fine transformation I will use some activation function.\n\n104\n00:10:27.463 --> 00:10:29.943\nThis is what has been done.\n\n105\n00:10:29.943 --> 00:10:35.543\nBut before we go into this, I wanted to show you this.\n"