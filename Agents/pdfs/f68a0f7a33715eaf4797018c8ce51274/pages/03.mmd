Moreover, we sought to simplify and streamline the construction of processing pipelines by overloading the bitwise OR operator. This approach is particularly advantageous as creating classes often necessitates writing boilerplate code, which is typically avoided, especially when dealing with complex filter chains or when the implementation of a neural network is not desired.

The following code snippet demonstrates the potential interfaces for implementing a simple filter chain:

from torch import nn from torch.nn import Sequential from torchfx.signal import Wave from torchfx.filter import ( HiShelving,  LoShelving, ) signal = Wave.from_file("path_to_file.mp3")

Implementation using classes: class FilterChain(nn.Module): def __init__(self, sample_rate): super()...init__(self) self.f1 = HiShelving(1000, sample_rate) self.f2 = LoShelving(2000, sample_rate)

 def forward(self, x): x = self.f1(x) x = self.f2(x) return x

fchain = FilterChain(signal.fs) result = fchain(signal.y)

Implementation using Sequential fchain = Sequential([  HiShelving(1000, sample_rate=signal.fs),  LoShelving(2000, sample_rate=signal.fs), ]) result = fchain(signal.y)

# Implementation using pipe operator result = signal \ | HiShelving(1000) \ | LoShelving(2000)

In the final example, the sample rate of the discrete filters is omitted, as it is lazily evaluated during filter application, thanks to the pipe operator. Alternatively, one can define the filter chain within Sequential without specifying the sampling frequency and subsequently apply the filters to the signal using the pipe operator. The operator overloading also manages the sampling frequency, rendering the process transparent:

Implementation using Sequential fchain = Sequential([  HiShelving(1000),  LoShelving(2000), ]) result = signal | fchain

## 4 Performance Evaluation

To evaluate the efficiency of our filter implementation within the TorchFX library, we conducted a benchmarking study comparing various Infinite Impulse Response (IIR) and Finite Impulse Response (FIR) filters against those provided by the SciPy library in conjunction with NumPy. Notably, libraries such as torchaudio and Julius were excluded from this analysis. The rationale for this exclusion lies in the fact that TorchFX is fundamentally based on torchaudio, making any direct comparison redundant, aside from minor overheads associated with wrapper classes. Additionally, other libraries like Julius, nnAudio, and Librosa were not included due to their lack of specificity in filter implementation. Julius, for example, only implements FIR filters, while both Librosa and nnAudio provide APIs that are excessively low-level and reliant on SciPy. Consequently, the only meaningful comparison was between SciPy and TorchFX.

Given TorchFX's dual capability to operate on both GPU and CPU platforms, our evaluation encompassed a tripartite comparison: TorchFX on CPU, TorchFX on GPU, and SciPy, focusing on the efficiency of FIR and IIR filter applications. Additionally, we conducted a benchmark to assess execution times across various interfaces as delineated in Section 3. These interfaces include the pipe operator, a class extending nn.Module, and a sequence of filters concatenated in nn.Sequential. The experimental tests were conducted on an Alienware Aurora R11 1.0.8 system, running Linux Ubuntu 22.04 with kernel version 6.8.0-57-generic. This system was equipped with an NVIDIA GeForce RTX 3070 graphics card featuring 8GB of VRAM, CUDA version 12.4, and an Intel i9-10900KF CPU operating at 5.3 GHz, complemented by 32 GB of RAM.

The benchmarking process was structured, with evaluations based on the average execution time derived from 50 repetitions of identical tasks. For each algorithm, three distinct implementations2 were tested: one utilizing solely SciPy and NumPy on the CPU, another employing TorchFX exclusively on the CPU, and a third leveraging TorchFX with execution, where feasible, on the GPU. To optimize pipeline efficiency, our measurements focused solely on the execution time of filter application on the signal, deliberately excluding the computation of filter coefficients and the reading of the signal into memory from the timing assessments. The performance evaluation of the IIR and FIR filters was conducted by varying the input signal's duration, ranging from 5 sec

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|} \hline Authors & Paper & Library & Filters & API & Signal Analysis & GPU \\ \hline Cheuk et al. & [7] & nnAudio & no & low-level & no & yes \\ Yang et al. & [5, 12] & torchaudio & yes & low-level & yes & yes \\ McFee et al. & [13] & librosa & no & low-level & yes & no \\ Virtanen et al. & [1] & scipy & yes & high-level & yes & no \\ \hline \end{tabular}
\end{table}
Table 1: Overview and Features of Major Audio Libraries.

